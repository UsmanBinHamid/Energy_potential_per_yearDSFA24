{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsx_EpEoNB4j"
      },
      "source": [
        "# Predicting Suitable Solar Energy Potential in Buildings of Karachi\n",
        "#### Solar installation stakeholders face significant challenges in assessing building potential, often requiring costly and time-consuming site surveys. This project addresses this challenge by analyzing the annual solar energy potential for Karachi's buildings using features from the data set.\n",
        "\n",
        "## Business Value\n",
        "\n",
        "#### Reduce assessment costs by quickly screening buildings for solar potential.\n",
        "#### \tSupport urban planning and renewable energy initiative\n",
        "#### Help property owners evaluate solar investment opportunities.\n",
        "#### Enable scalable solar adoption strategies across Karachi.i\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bo11Tq-JNB4l",
        "outputId": "318fdee4-4f37-4dc2-cf00-e5b54153035b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Object `Karachi` not found.\n",
            "Object `types` not found.\n",
            "Object `placement` not found.\n",
            "Object `installations` not found.\n",
            "Object `efficiency` not found.\n"
          ]
        }
      ],
      "source": [
        "# Business Questions\n",
        "\n",
        "1.\tHow can the surface area of rooftops be optimized for maximizing the potential installable area for solar panels in Karachi?\n",
        "3.\tHow does the energy potential per year vary across different assumed building types?\n",
        "4.\tWhat is the relationship between estimated building height and energy potential per year for optimizing solar panel placement?\n",
        "5.\tHow can businesses leverage the estimated capacity factor to predict the efficiency and performance of solar installations?\n",
        "7.\tHow does the estimated tilt of rooftops affect the energy potential per year and what adjustments can maximize efficiency?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7ke6JDCONB4l",
        "outputId": "4078c0d6-efd0-403b-f85b-b968b81a30c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'karachi_rooftop_solar_potential.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-26e8b2cb9300>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor_codes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"karachi_rooftop_solar_potential.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m#To display the top 5 rows df.head(5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'karachi_rooftop_solar_potential.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score,mean_squared_error, r2_score,mean_absolute_error\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor,plot_tree\n",
        "sns.set(color_codes=True)\n",
        "\n",
        "df=pd.read_csv(\"karachi_rooftop_solar_potential.csv\")\n",
        "#To display the top 5 rows df.head(5)\n",
        "\n",
        "df.head(5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "0ePMGiWwVBhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLJm84BsNB4l"
      },
      "source": [
        "# Data Source\n",
        "#### This dataset contains solar rooftop potential data at individual building structure levels for a sample area of interest in Karachi. The data was gathered by extracting building rooftop footprint polygons from very high-resolution satellite stereo imagery of 0.5m resolution. The rooftop angle, obstruction, and shading were taken into account during suitable area calculation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2TRr9v0NB4m"
      },
      "source": [
        "# Source (https://energydata.info)\n",
        "\n",
        "URL:https://energydata.info/dataset/karachi-rooftop-solar-potential-mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ivFn4IGNB4m"
      },
      "outputs": [],
      "source": [
        "df.dtypes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ak_JJAxNB4m"
      },
      "source": [
        "- Surface_area: Total Surface area\n",
        "- Potential_installable_area:Area in which panel can be placed\n",
        "- Estimated_building_height:Height of Building\n",
        "- Estimated_tilt:the angle at which panel is placed\n",
        "- Assumed_building_type (encoded):Type of building\n",
        "- Peak_installable_capacity:maximum capacity of kv to install  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsW83KQCNB4m"
      },
      "outputs": [],
      "source": [
        "print(df.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0O_byK1NB4n"
      },
      "outputs": [],
      "source": [
        "## city is duplicate for all\n",
        "df2 = df.pivot_table(index = ['City'], aggfunc ='size')\n",
        "print(\"Get count of duplicate values in multiple columns:\\n\", df2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cANvcLanNB4n"
      },
      "outputs": [],
      "source": [
        "df=df.drop(['Comment', 'uuid','Unit_installation_price','City'], axis=1)\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmHZKKSiNB4n"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "duplicate_rows_df = df [df.duplicated()]\n",
        "\n",
        "print(\"number of duplicate rows:\", duplicate_rows_df.size)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xi80he84NB4n"
      },
      "outputs": [],
      "source": [
        "print(df.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBSWWkTiNB4o"
      },
      "outputs": [],
      "source": [
        "df['Estimated_building_height'] = df['Estimated_building_height'].fillna(df.groupby('Assumed_building_type')['Estimated_building_height'].transform('mean'))\n",
        "#Median\n",
        "df['Estimated_capacity_factor'] = df['Estimated_capacity_factor'].fillna(df.groupby('Assumed_building_type')['Estimated_capacity_factor'].transform('mean'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8uJBHLkNB4o"
      },
      "outputs": [],
      "source": [
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pntKNs0uNB4o"
      },
      "outputs": [],
      "source": [
        "df.Assumed_building_type.value_counts().nlargest(100).plot(kind='bar', figsize=(10,5))\n",
        "plt.title(\"Data vs \")\n",
        "plt.ylabel('Max number of building type')\n",
        "plt.xlabel('Assumed_building_type');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7iua-0uNB4o"
      },
      "outputs": [],
      "source": [
        "numeric_cols = ['Surface_area', 'Potential_installable_area', 'Peak_installable_capacity',\n",
        "                'Energy_potential_per_year', 'Estimated_building_height']\n",
        "correlation = df[numeric_cols].corr()\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(correlation, annot=True, cmap='coolwarm', center=0)\n",
        "plt.title('Correlation Matrix of Key Metrics')\n",
        "plt.tight_layout()\n",
        "\n",
        "#high colarted\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7EnS0wSNB4o"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 15))\n",
        "\n",
        "# 1. Surface Area vs Energy Potential Scatter Plot\n",
        "plt.subplot(2, 2, 1)\n",
        "sns.scatterplot(data=df, x='Surface_area', y='Energy_potential_per_year',\n",
        "                hue='Assumed_building_type', alpha=0.6)\n",
        "plt.title('Surface Area vs Energy Potential by Building Type')\n",
        "plt.xlabel('Surface Area')\n",
        "plt.ylabel('Energy Potential per Year')\n",
        "\n",
        "## they are co related"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgD4FvUONB4o"
      },
      "outputs": [],
      "source": [
        "# 2. Building Height Distribution\n",
        "plt.subplot(1, 1,1)\n",
        "sns.boxplot(data=df, x='Assumed_building_type', y='Estimated_building_height')\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Building Height Distribution by Type')\n",
        "plt.xlabel('Building Type')\n",
        "plt.ylabel('Estimated Height')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KubrxcsNB4o"
      },
      "outputs": [],
      "source": [
        "# 3. Capacity Factor Distribution\n",
        "plt.subplot(2, 2, 3)\n",
        "sns.histplot(data=df[df['Estimated_capacity_factor'].notna()],\n",
        "             x='Estimated_capacity_factor', bins=20)\n",
        "plt.title('Distribution of Estimated Capacity Factor')\n",
        "plt.xlabel('Capacity Factor')\n",
        "plt.ylabel('Count')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8RLjlL3NB4o"
      },
      "outputs": [],
      "source": [
        "# 4. Installation Area Efficiency\n",
        "df['Installation_efficiency'] = (df['Potential_installable_area'] / df['Surface_area']) * 100\n",
        "plt.subplot(2, 2, 4)\n",
        "sns.violinplot(data=df, x='Assumed_building_type', y='Installation_efficiency')\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Installation Area Efficiency by Building Type')\n",
        "plt.xlabel('Building Type')\n",
        "plt.ylabel('Installation Efficiency (%)')\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4L-JCeKiNB4o"
      },
      "outputs": [],
      "source": [
        "# Additional analysis: Energy potential per surface area\n",
        "print(\"\\nAverage Energy Potential per Surface Area by Building Type:\")\n",
        "efficiency_by_type = df.groupby('Assumed_building_type').agg({\n",
        "    'Energy_potential_per_year': 'sum',\n",
        "    'Surface_area': 'sum'\n",
        "}).assign(\n",
        "    energy_density=lambda x: x['Energy_potential_per_year'] / x['Surface_area']\n",
        ").round(2)\n",
        "print(efficiency_by_type['energy_density'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJkmBuI7NB4o"
      },
      "outputs": [],
      "source": [
        "\n",
        "groupeddf=df.groupby('Assumed_building_type')\n",
        " # Calculate efficiency score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWp2fmZDNB4o"
      },
      "outputs": [],
      "source": [
        "for key, count in groupeddf:\n",
        "    print(key+\" : \" + str(count['Assumed_building_type'].count()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWYJ6lVSNB4p"
      },
      "outputs": [],
      "source": [
        "groupedAVG=groupeddf.agg({\n",
        "            'Surface_area': 'mean',\n",
        "            'Potential_installable_area': 'mean',\n",
        "            'Peak_installable_capacity': 'mean',\n",
        "            'Energy_potential_per_year': 'mean',\n",
        "            'Estimated_building_height':'mean',\n",
        "            'Estimated_capacity_factor':\"mean\",\n",
        "            'Estimated_tilt':\"mean\",\n",
        "        }).to_dict(orient='index'),"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWPukvOINB4p"
      },
      "outputs": [],
      "source": [
        "print(\"Avg Space Utilized\")\n",
        "for key, avg_space_utilization in groupeddf:\n",
        "  space=(avg_space_utilization['Potential_installable_area'].sum() / df['Surface_area'].sum() * 100)\n",
        "  print(\"for \" + key + \":\" + str(space) + \"%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4hXYxNnNB4p"
      },
      "outputs": [],
      "source": [
        "#'buildings_with_zero_potential': ,\n",
        "print(\"buildings with zero potential\")\n",
        "for key, buildings_with_zero_potential in groupeddf:\n",
        "  zero=len(buildings_with_zero_potential[buildings_with_zero_potential['Energy_potential_per_year'] == 0])\n",
        "  print(\"in \" + key + \":\" + str(zero))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "is6VLUEMNB4p"
      },
      "outputs": [],
      "source": [
        "#'buildings_with_high_potential': len(dfcopy[dfcopy['Energy_potential_per_year'] > dfcopy['Energy_potential_per_year'].mean()])\n",
        "\n",
        "print(\"buildings with high potential\")\n",
        "for key, buildings_with_high_potential in groupeddf:\n",
        "  high=len(buildings_with_high_potential[buildings_with_high_potential['Energy_potential_per_year'] > buildings_with_high_potential['Energy_potential_per_year'].mean()])\n",
        "  print(key + \":\" + str(high))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QP4AvqoNB4p"
      },
      "outputs": [],
      "source": [
        "pivot_table = pd.pivot_table(\n",
        "    df,\n",
        "    values=[\n",
        "        'Surface_area',\n",
        "        'Potential_installable_area',\n",
        "        'Peak_installable_capacity',\n",
        "        'Energy_potential_per_year',\n",
        "        'Estimated_building_height',\n",
        "        'Estimated_capacity_factor',\n",
        "        'Estimated_tilt',\n",
        "    ],\n",
        "    index=['Assumed_building_type'],  # Replace with your actual grouping column name\n",
        "    aggfunc='mean'\n",
        ")\n",
        "\n",
        "print(pivot_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4LssD8gNB4p"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def analyze_surface_area_optimization():\n",
        "    \"\"\"Analyze surface area utilization and optimization potential\"\"\"\n",
        "    # Calculate utilization ratio\n",
        "    df['utilization_ratio'] = df['Potential_installable_area'] / df['Surface_area'] * 100\n",
        "\n",
        "    # Group by building type and calculate mean metrics\n",
        "    utilization_analysis = df.groupby('Assumed_building_type').agg({\n",
        "        'Surface_area': 'mean',\n",
        "        'Potential_installable_area': 'mean',\n",
        "        'utilization_ratio': 'mean'\n",
        "    }).round(2)\n",
        "\n",
        "    # Calculate efficiency score\n",
        "    utilization_analysis['efficiency_score'] = (\n",
        "        utilization_analysis['utilization_ratio'] *\n",
        "        utilization_analysis['Potential_installable_area']\n",
        "    ).round(2)\n",
        "\n",
        "    return utilization_analysis\n",
        "\n",
        "def analyze_energy_potential_by_building():\n",
        "    \"\"\"Analyze energy potential across different building types\"\"\"\n",
        "    energy_analysis = df.groupby('Assumed_building_type').agg({\n",
        "        'Energy_potential_per_year': ['mean', 'sum'],\n",
        "        'Surface_area': 'mean',\n",
        "        'Peak_installable_capacity': 'mean'\n",
        "    }).round(2)\n",
        "\n",
        "    # Calculate energy efficiency ratio\n",
        "    energy_analysis['energy_per_area'] = (\n",
        "        energy_analysis[('Energy_potential_per_year', 'sum')] /\n",
        "        energy_analysis[('Surface_area', 'mean')]\n",
        "    ).round(2)\n",
        "\n",
        "    return energy_analysis\n",
        "\n",
        "\n",
        "\n",
        "def analyze_capacity_factor():\n",
        "    \"\"\"Analyze capacity factor patterns and implications\"\"\"\n",
        "    capacity_analysis = df.groupby('Assumed_building_type').agg({\n",
        "        'Estimated_capacity_factor': ['mean', 'std'],\n",
        "        'Energy_potential_per_year': 'mean'\n",
        "    }).round(2)\n",
        "\n",
        "    # Calculate performance efficiency\n",
        "    capacity_analysis['performance_ratio'] = (\n",
        "        capacity_analysis[('Energy_potential_per_year', 'mean')] /\n",
        "        capacity_analysis[('Estimated_capacity_factor', 'mean')]\n",
        "    ).round(2)\n",
        "\n",
        "    return capacity_analysis\n",
        "\n",
        "def analyze_tilt_impact():\n",
        "    \"\"\"Analyze the impact of tilt on energy potential\"\"\"\n",
        "    # Since all tilts are same, we'll calculate theoretical optimal tilt\n",
        "    # Based on Karachi's latitude (24.8607Â° N)\n",
        "    latitude = 24.8607\n",
        "    optimal_tilt = latitude * 0.76  # General rule of thumb for optimal tilt\n",
        "\n",
        "    tilt_analysis = {\n",
        "        'current_tilt': df['Estimated_tilt'].mean(),\n",
        "        'optimal_tilt': optimal_tilt,\n",
        "        'tilt_difference': optimal_tilt - df['Estimated_tilt'].mean(),\n",
        "        'potential_improvement': abs(optimal_tilt - df['Estimated_tilt'].mean()) * 0.5  # Estimated improvement percentage\n",
        "    }\n",
        "\n",
        "    return tilt_analysis\n",
        "\n",
        "\n",
        "# Print results with insights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lx6Y-2hmNB4p"
      },
      "outputs": [],
      "source": [
        "print(\"1. Surface Area Optimization Analysis:\")\n",
        "print( analyze_surface_area_optimization())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JU5kY5xNB4p"
      },
      "outputs": [],
      "source": [
        "print(\"\\n2. Energy Potential by Building Type:\")\n",
        "print( analyze_energy_potential_by_building())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYLyFvuCNB4p"
      },
      "outputs": [],
      "source": [
        "print(\"\\n5. Tilt Impact Analysis:\")\n",
        "print( analyze_tilt_impact())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMH2wlznNB4p"
      },
      "outputs": [],
      "source": [
        "features = ['Surface_area', 'Potential_installable_area', 'Peak_installable_capacity',\n",
        "                        'Estimated_tilt', 'Estimated_building_height', 'Estimated_capacity_factor']\n",
        "\n",
        "X = df[features]\n",
        "y = df['Energy_potential_per_year']\n",
        "\n",
        "        # Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8-dQWTNNB4p"
      },
      "outputs": [],
      "source": [
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIoIuSjSNB4p"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def evaluate_model(model_name, model, X_train, X_test, y_train, y_test):\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"{model_name} Analysis\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    # Train model\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Create bins for classification metrics\n",
        "    y_test_binned = pd.qcut(y_test, q=4, labels=['Low', 'Medium', 'High', 'Very High'])\n",
        "    y_pred_binned = pd.qcut(y_pred, q=4, labels=['Low', 'Medium', 'High', 'Very High'])\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test_binned, y_pred_binned)\n",
        "\n",
        "    # Print classification report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test_binned, y_pred_binned))\n",
        "\n",
        "    # Print accuracy\n",
        "    print(f\"\\nAccuracy Score: {accuracy:.4f}\")\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    cm = confusion_matrix(y_test_binned, y_pred_binned)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Low', 'Medium', 'High', 'Very High'],\n",
        "                yticklabels=['Low', 'Medium', 'High', 'Very High'])\n",
        "    plt.title(f'{model_name} Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Return model and predictions for further analysis\n",
        "    return model, y_pred, accuracy\n",
        "\n",
        "def analyze_linear_regression(X_train, X_test, y_train, y_test):\n",
        "    model = LinearRegression()\n",
        "    return evaluate_model('Linear Regression', model, X_train, X_test, y_train, y_test)\n",
        "\n",
        "def analyze_ridge_regression(X_train, X_test, y_train, y_test):\n",
        "    model = Ridge()\n",
        "    return evaluate_model('Ridge Regression', model, X_train, X_test, y_train, y_test)\n",
        "\n",
        "def analyze_lasso_regression(X_train, X_test, y_train, y_test):\n",
        "    model = Lasso()\n",
        "    return evaluate_model('Lasso Regression', model, X_train, X_test, y_train, y_test)\n",
        "\n",
        "def analyze_decision_tree(X_train, X_test, y_train, y_test, feature_names):\n",
        "    model = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
        "    trained_model, y_pred, accuracy = evaluate_model('Decision Tree', model, X_train, X_test, y_train, y_test)\n",
        "\n",
        "    # Plot decision tree\n",
        "    plt.figure(figsize=(20,10))\n",
        "    plot_tree(trained_model, feature_names=feature_names, filled=True, rounded=True, fontsize=10)\n",
        "    plt.title(\"Decision Tree Structure\")\n",
        "    plt.show()\n",
        "\n",
        "    # Print feature importance\n",
        "    importance = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Importance': trained_model.feature_importances_\n",
        "    }).sort_values('Importance', ascending=False)\n",
        "    print(\"\\nFeature Importance:\")\n",
        "    print(importance)\n",
        "\n",
        "    return trained_model, y_pred, accuracy\n",
        "\n",
        "def analyze_random_forest(X_train, X_test, y_train, y_test, feature_names):\n",
        "    model = RandomForestRegressor(n_estimators=5, random_state=42)\n",
        "    trained_model, y_pred, accuracy = evaluate_model('Random Forest', model, X_train, X_test, y_train, y_test)\n",
        "\n",
        "    # Print feature importance\n",
        "    importance = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Importance': trained_model.feature_importances_\n",
        "    }).sort_values('Importance', ascending=False)\n",
        "    print(\"\\nFeature Importance:\")\n",
        "    print(importance)\n",
        "\n",
        "    return trained_model, y_pred, accuracy\n",
        "\n",
        "def analyze_gradient_boosting(X_train, X_test, y_train, y_test, feature_names):\n",
        "    model = GradientBoostingRegressor(random_state=42)\n",
        "    trained_model, y_pred, accuracy = evaluate_model('Gradient Boosting', model, X_train, X_test, y_train, y_test)\n",
        "\n",
        "    # Print feature importance\n",
        "    importance = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Importance': trained_model.feature_importances_\n",
        "    }).sort_values('Importance', ascending=False)\n",
        "    print(\"\\nFeature Importance:\")\n",
        "    print(importance)\n",
        "\n",
        "    return trained_model, y_pred, accuracy\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7cpclBHNB4q"
      },
      "outputs": [],
      "source": [
        "results = {}\n",
        "\n",
        " # Run all models\n",
        "results['Linear Regression'] = analyze_linear_regression(X_train, X_test, y_train, y_test)\n",
        "\n",
        "\n",
        "# Run the analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6nptnr3NB4q"
      },
      "outputs": [],
      "source": [
        "results['Ridge Regression'] = analyze_ridge_regression(X_train, X_test, y_train, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkxzloflNB4q"
      },
      "outputs": [],
      "source": [
        "results['Lasso Regression'] = analyze_lasso_regression(X_train, X_test, y_train, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2rEbFKgNB4q"
      },
      "outputs": [],
      "source": [
        "results['Random Forest'] = analyze_random_forest(X_train, X_test, y_train, y_test, features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SohF8TgoNB4t"
      },
      "outputs": [],
      "source": [
        "results['Gradient Boosting'] = analyze_gradient_boosting(X_train, X_test, y_train, y_test, features)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKEaFP7BNB4t"
      },
      "outputs": [],
      "source": [
        "\n",
        "accuracies = pd.DataFrame({\n",
        "     'Model': results.keys(),\n",
        "     'Accuracy': [result[2] for result in results.values()]\n",
        " }).sort_values('Accuracy', ascending=False)\n",
        "\n",
        "print(\"\\nModel Accuracy Comparison:\")\n",
        "print(\"=========================\")\n",
        "print(accuracies)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ptf00lItNB4t"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Function to train decision tree and get performance metrics\n",
        "def train_and_evaluate_decision_tree():  # Reduced max_depth for better visualization\n",
        "\n",
        "    dt_model = DecisionTreeRegressor(max_depth=3, random_state=42)\n",
        "    dt_model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = dt_model.predict(X_test)\n",
        "\n",
        "    # Calculate performance metrics\n",
        "    metrics = {\n",
        "        'R2 Score': r2_score(y_test, y_pred),\n",
        "        'Mean Squared Error': mean_squared_error(y_test, y_pred),\n",
        "        'Root Mean Squared Error': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
        "        'Mean Absolute Error': mean_absolute_error(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "    # Feature importance\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'Feature': X.columns,\n",
        "        'Importance': dt_model.feature_importances_\n",
        "    }).sort_values('Importance', ascending=False)\n",
        "\n",
        "    return metrics, feature_importance,dt_model\n",
        "\n",
        "# Function to visualize decision tree\n",
        "def visualize_tree(model, feature_names):\n",
        "    plt.figure(figsize=(20,10))\n",
        "    plot_tree(model,\n",
        "             feature_names=feature_names,\n",
        "             filled=True,\n",
        "             rounded=True,\n",
        "             fontsize=10)\n",
        "    plt.title(\"Decision Tree Visualization\")\n",
        "    plt.show();\n",
        "\n",
        "# Load and prepare the data\n",
        "\n",
        "# Train model and get metrics\n",
        "metrics, feature_importance,dTmodel = train_and_evaluate_decision_tree()\n",
        "\n",
        "# Print results\n",
        "print(\"\\nDecision Tree Performance Metrics:\")\n",
        "for metric, value in metrics.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "print(\"\\nFeature Importance:\")\n",
        "print(feature_importance)\n",
        "\n",
        "# Visualize the tree\n",
        "visualize_tree(dTmodel, features)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}